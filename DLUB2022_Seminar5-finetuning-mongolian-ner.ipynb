{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Deep Learning Ulaanbaatar (DLUB) 2022 - Summer School üá≤üá≥\n**Seminar: Mongolian Named Entity Recognition (NER) using HuggingFace Transformers **\n\n–ë–∏–¥ –Ω–∞—Ä —é—É —Ö–∏–π—Ö –≥—ç–∂ –±–∞–π–≥–∞–∞ –≤—ç?\n1. Named entity recognition –ú–æ–Ω–≥–æ–ª —Ö—ç–ª –¥—ç—ç—Ä Transformers –∞—à–∏–≥–ª–∞–Ω —Å—É—Ä–≥–∞–∂ “Ø–∑—ç—Ö –≥—ç–∂ –±–∞–π–Ω–∞.\n2. ”®–º–Ω”© –Ω—å MLM task –¥—ç—ç—Ä —Å—É—Ä—Å–∞–Ω Encoder model –∞—à–∏–≥–ª–∞–Ω–∞.\n3. Fine-tune —Ö–∏–π—Ö–∏–π–≥ —Å—É—Ä–Ω–∞.\n\n–≠–Ω—ç—Ö“Ø“Ø notebook –Ω—å NER task-–¥ —Ç—É—Å–≥–∞–π–ª–∞–Ω –±—ç–ª–¥—Å—ç–Ω –¥–∞—Ç–∞–≥“Ø–π–≥—ç—ç—Ä –±–æ–ª–æ–º–∂–≥“Ø–π —é–º. –î–∞—Ç–∞–≥ –±—ç–ª–¥—ç–∂ –∏–ª –±–æ–ª–≥–æ—Å–æ–Ω [–¢”©–≥”©–ª–¥”©—Ä](https://github.com/tugstugi) –±–æ–ª–æ–Ω [–≠–Ω–æ–¥](https://github.com/enod) –Ω–∞—Ä—Ç –±–∞—è—Ä–ª–∞–ª–∞–∞! üôá","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"# for huggingface hub integration\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf_token\")\n\n!apt install git-lfs\n!git lfs install\n!pip install seqeval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-01T01:12:39.831908Z","iopub.execute_input":"2022-07-01T01:12:39.832439Z","iopub.status.idle":"2022-07-01T01:13:07.169616Z","shell.execute_reply.started":"2022-07-01T01:12:39.832304Z","shell.execute_reply":"2022-07-01T01:13:07.168135Z"},"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport json\n\nimport datasets\nimport numpy as np\nimport pandas as pd\nfrom datasets import ClassLabel, load_dataset, load_metric\n\nimport transformers\nfrom transformers import (\n    AutoConfig,\n    AutoModelForTokenClassification,\n    AutoTokenizer,\n    DataCollatorForTokenClassification,\n    HfArgumentParser,\n    PretrainedConfig,\n    PreTrainedTokenizerFast,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:07.171920Z","iopub.execute_input":"2022-07-01T01:13:07.172301Z","iopub.status.idle":"2022-07-01T01:13:14.520271Z","shell.execute_reply.started":"2022-07-01T01:13:07.172264Z","shell.execute_reply":"2022-07-01T01:13:14.519290Z"},"_kg_hide-input":true,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## ”®–≥”©–≥–¥–ª”©”© –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö\n\n–≠–Ω—ç—Ö“Ø“Ø –¥–∞—Ç–∞–≥ –±—ç–ª–¥—Å—ç–Ω \n\n```json\n{\n    \"text\": \"–•–∞—Ä–∏–Ω \\\"–¢–∞–≤–∞–Ω—Ç–æ–ª–≥–æ–π\\\" –•–ö-–∏–π–Ω —É—É—Ä—Ö–∞–π—á–∏–¥ 2017 –æ–Ω–¥ 141 —Ç—ç—Ä–±—É–º —Ç”©–≥—Ä”©–≥–∏–π–Ω –∞—à–∏–≥—Ç–∞–π –∞–∂–∏–ª–ª–∞–∞–¥ —É–¥–∞—Ö–≥“Ø–π —Ö—É–≤—å—Ü–∞–∞ —ç–∑—ç–º—à–∏–≥—á–¥–∏–π–Ω—Ö—ç—ç —Ö—É—Ä–ª—ã–≥ —Ö–∏–π–∂ –Ω–æ–≥–¥–æ–ª –∞—à–≥–∞–∞ —Ö—É–≤–∞–∞—Ä–∏–ª–∞—Ö —é–º –±–∞–π–Ω–∞.\"\n    \"labels\":[\n        [\n            7\n            18\n            string\"ORG\"\n        ],..\n    ]\n}\n```\n–¢–∞–π–ª–±–∞—Ä: –≠–Ω—ç —Ç–æ—Ö–∏–æ–ª–¥–æ–ª–¥ `text` field-–∏–π–Ω 7-18 —Ö–æ–æ—Ä–æ–Ω–¥–æ—Ö-—Ä substring –Ω—å ORG –±—É—é—É Organization.\n```bash\n0123456[7..........]18...\n–•–∞—Ä–∏–Ω \"[–¢–∞–≤–∞–Ω—Ç–æ–ª–≥–æ–π]\" –•–ö-–∏–π–Ω —É—É—Ä—Ö–∞–π—á–∏–¥...\n```\n\n–î–∞—Ç–∞–≥ –∞—à–∏–≥–ª–∞—Ö–∞–¥ –∞–º–∞—Ä –±–∞–π–ª–≥–∞—Ö –∑–æ—Ä–∏–ª–≥–æ–æ—Ä –¥–∞—Ä–∞–∞—Ö –±–∞–π–¥–ª–∞–∞—Ä kaggle dataset –±–æ–ª–≥–æ–Ω –±–∞–π—Ä–ª—É—É–ª–∞–≤.\nhttps://www.kaggle.com/datasets/bayartsogtya/mongolian-ner-v1 ","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/mongolian-ner-v1/NER_v1.0.json', 'r') as reader:\n    lines = reader.readlines()\nlines = [json.loads(x) for x in lines]","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:14.521942Z","iopub.execute_input":"2022-07-01T01:13:14.522660Z","iopub.status.idle":"2022-07-01T01:13:14.651583Z","shell.execute_reply.started":"2022-07-01T01:13:14.522618Z","shell.execute_reply":"2022-07-01T01:13:14.650524Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# find all unique tags\nlabels = set()\nfor line in lines:\n    for s, e, label in line['labels']:\n        labels.add(label)\n\nlabels = sorted(list(labels))\nlabels = ['O'] + labels\nlabel2idx = {x:i for i,x in enumerate(labels)}\nidx2label = {i:x for i,x in enumerate(labels)}\nnum_labels = len(labels)\nprint(num_labels)\nprint(labels)\nprint(label2idx)\nprint(idx2label)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:14.653596Z","iopub.execute_input":"2022-07-01T01:13:14.654074Z","iopub.status.idle":"2022-07-01T01:13:14.669723Z","shell.execute_reply.started":"2022-07-01T01:13:14.654034Z","shell.execute_reply":"2022-07-01T01:13:14.668457Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"token_list = []\nner_tag_list = []\n\nfor line in lines:\n    labels = line['labels']\n    text = line['text']\n    \n    labels.sort()\n    labels = [[-1, -1, '']] + labels + [[len(text), len(text), '']]\n\n    tokens = []\n    tags = []\n    for pre, cur in zip(labels, labels[1:]):\n        ps, pe, pl = pre\n        cs, ce, cl = cur\n        \n        ll = text[pe+1: cs].strip().split(' ')\n        tokens += ll\n        tags += [0] * len(ll)\n        \n        if cl:\n            ll = text[cs: ce].strip().split(' ')\n            tokens += ll\n            tags += [label2idx[cl]] * len(ll)\n    token_list.append(tokens)\n    ner_tag_list.append(tags)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:19.551196Z","iopub.execute_input":"2022-07-01T01:13:19.551622Z","iopub.status.idle":"2022-07-01T01:13:19.862397Z","shell.execute_reply.started":"2022-07-01T01:13:19.551588Z","shell.execute_reply":"2022-07-01T01:13:19.861359Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(token_list[10])\nprint(ner_tag_list[10])","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:28.407307Z","iopub.execute_input":"2022-07-01T01:13:28.407680Z","iopub.status.idle":"2022-07-01T01:13:28.413403Z","shell.execute_reply.started":"2022-07-01T01:13:28.407649Z","shell.execute_reply":"2022-07-01T01:13:28.412451Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## pandas.DataFrame-—ç—ç—Å HF Dataset “Ø“Ø—Å–≥—ç—Ö","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['tokens'] = token_list\ndf['ner_tags'] = ner_tag_list\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:34.019435Z","iopub.execute_input":"2022-07-01T01:13:34.020125Z","iopub.status.idle":"2022-07-01T01:13:34.069400Z","shell.execute_reply.started":"2022-07-01T01:13:34.020088Z","shell.execute_reply":"2022-07-01T01:13:34.068313Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nraw_dataset = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:35.010686Z","iopub.execute_input":"2022-07-01T01:13:35.011623Z","iopub.status.idle":"2022-07-01T01:13:35.084666Z","shell.execute_reply.started":"2022-07-01T01:13:35.011576Z","shell.execute_reply":"2022-07-01T01:13:35.083612Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"raw_dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:36.087359Z","iopub.execute_input":"2022-07-01T01:13:36.087988Z","iopub.status.idle":"2022-07-01T01:13:36.095281Z","shell.execute_reply.started":"2022-07-01T01:13:36.087951Z","shell.execute_reply":"2022-07-01T01:13:36.094065Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## –ë—ç–ª—Ç–≥—ç–ª\n\n- config, tokenizer, model from huggingface model hub\n- model card: https://huggingface.co/bayartsogt/mongolian-roberta-base (trained data: OSCAR deduplicated_mn)","metadata":{}},{"cell_type":"code","source":"model_name = 'bayartsogt/mongolian-roberta-base'","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:37.569118Z","iopub.execute_input":"2022-07-01T01:13:37.569862Z","iopub.status.idle":"2022-07-01T01:13:37.574624Z","shell.execute_reply.started":"2022-07-01T01:13:37.569824Z","shell.execute_reply":"2022-07-01T01:13:37.573278Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\n    model_name,\n    num_labels=num_labels,\n    finetuning_task='ner',\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:39.600826Z","iopub.execute_input":"2022-07-01T01:13:39.601192Z","iopub.status.idle":"2022-07-01T01:13:41.693912Z","shell.execute_reply.started":"2022-07-01T01:13:39.601162Z","shell.execute_reply":"2022-07-01T01:13:41.692961Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    use_fast=True,\n    add_prefix_space=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:41.695997Z","iopub.execute_input":"2022-07-01T01:13:41.696657Z","iopub.status.idle":"2022-07-01T01:13:59.243719Z","shell.execute_reply.started":"2022-07-01T01:13:41.696620Z","shell.execute_reply":"2022-07-01T01:13:59.242586Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    model_name,\n    config=config,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:13:59.247802Z","iopub.execute_input":"2022-07-01T01:13:59.248489Z","iopub.status.idle":"2022-07-01T01:14:37.041799Z","shell.execute_reply.started":"2022-07-01T01:13:59.248458Z","shell.execute_reply":"2022-07-01T01:14:37.040752Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.config.label2id = label2idx\nmodel.config.id2label = idx2label","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:14:37.043406Z","iopub.execute_input":"2022-07-01T01:14:37.044371Z","iopub.status.idle":"2022-07-01T01:14:37.053358Z","shell.execute_reply.started":"2022-07-01T01:14:37.044322Z","shell.execute_reply":"2022-07-01T01:14:37.049646Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"text_column_name = 'tokens'\nlabel_column_name = 'ner_tags'\nprint(raw_dataset[2][text_column_name])\nprint(raw_dataset[2][label_column_name])","metadata":{"execution":{"iopub.status.busy":"2022-07-01T02:22:38.244433Z","iopub.execute_input":"2022-07-01T02:22:38.245189Z","iopub.status.idle":"2022-07-01T02:22:38.253722Z","shell.execute_reply.started":"2022-07-01T02:22:38.245153Z","shell.execute_reply":"2022-07-01T02:22:38.252507Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Tokenize all texts and align the labels with them.\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[text_column_name],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128,\n        is_split_into_words=True,\n    )\n    labels = []\n    for i, label in enumerate(examples[label_column_name]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            else:\n                label_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:14:45.194090Z","iopub.execute_input":"2022-07-01T01:14:45.194903Z","iopub.status.idle":"2022-07-01T01:14:45.204559Z","shell.execute_reply.started":"2022-07-01T01:14:45.194851Z","shell.execute_reply":"2022-07-01T01:14:45.203431Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# tokenized_dataset = raw_dataset.select(range(10)).map(\ntokenized_dataset = raw_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=2,\n    desc=\"Running tokenizer on train dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:14:46.390547Z","iopub.execute_input":"2022-07-01T01:14:46.391306Z","iopub.status.idle":"2022-07-01T01:14:50.018871Z","shell.execute_reply.started":"2022-07-01T01:14:46.391262Z","shell.execute_reply":"2022-07-01T01:14:50.017795Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(len(tokenized_dataset[0]['input_ids']))\nprint(len(tokenized_dataset[0]['labels']))\nprint(tokenized_dataset[0]['input_ids'])\nprint(tokenized_dataset[0]['labels'])","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:14:50.421806Z","iopub.execute_input":"2022-07-01T01:14:50.423913Z","iopub.status.idle":"2022-07-01T01:14:50.432697Z","shell.execute_reply.started":"2022-07-01T01:14:50.423832Z","shell.execute_reply":"2022-07-01T01:14:50.431444Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# all_dataset = tokenized_dataset.select(range(300)).train_test_split()\nall_dataset = tokenized_dataset.train_test_split()\nall_dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:15:08.922818Z","iopub.execute_input":"2022-07-01T01:15:08.923418Z","iopub.status.idle":"2022-07-01T01:15:08.949476Z","shell.execute_reply.started":"2022-07-01T01:15:08.923373Z","shell.execute_reply":"2022-07-01T01:15:08.948460Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## HuggingFace Trainer —Ö—ç—Ä—ç–≥–ª—ç—ç","metadata":{}},{"cell_type":"code","source":"# Data collator\ndata_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=None)\n\n# Metrics\nmetric = load_metric(\"seqeval\")\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [labels[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [labels[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:15:10.342569Z","iopub.execute_input":"2022-07-01T01:15:10.343328Z","iopub.status.idle":"2022-07-01T01:15:12.180871Z","shell.execute_reply.started":"2022-07-01T01:15:10.343270Z","shell.execute_reply":"2022-07-01T01:15:12.179917Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"OUTPUT_MODEL = 'roberta-base-ner-demo'\n\ntraining_args = TrainingArguments(\n    OUTPUT_MODEL,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16*2,\n    dataloader_num_workers=2,\n\n    evaluation_strategy = \"epoch\",\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    report_to='tensorboard',\n    log_level=\"warning\",\n\n    # automatic version handling with huggingface\n    push_to_hub=True,\n    hub_token=hf_token,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:15:12.579603Z","iopub.execute_input":"2022-07-01T01:15:12.580193Z","iopub.status.idle":"2022-07-01T01:15:12.648967Z","shell.execute_reply.started":"2022-07-01T01:15:12.580157Z","shell.execute_reply":"2022-07-01T01:15:12.647602Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Set seed before initializing model.\nset_seed(training_args.seed)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:15:16.151156Z","iopub.execute_input":"2022-07-01T01:15:16.151521Z","iopub.status.idle":"2022-07-01T01:15:16.156837Z","shell.execute_reply.started":"2022-07-01T01:15:16.151483Z","shell.execute_reply":"2022-07-01T01:15:16.155811Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Initialize our Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=all_dataset['train'],\n    eval_dataset=all_dataset['test'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:15:16.966851Z","iopub.execute_input":"2022-07-01T01:15:16.967967Z","iopub.status.idle":"2022-07-01T01:15:33.203662Z","shell.execute_reply.started":"2022-07-01T01:15:16.967915Z","shell.execute_reply":"2022-07-01T01:15:33.202407Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:15:33.206320Z","iopub.execute_input":"2022-07-01T01:15:33.207136Z","iopub.status.idle":"2022-07-01T01:47:52.233231Z","shell.execute_reply.started":"2022-07-01T01:15:33.207088Z","shell.execute_reply":"2022-07-01T01:47:52.232057Z"},"_kg_hide-output":true,"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!cd roberta-base-ner && git pull","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:50:54.066899Z","iopub.execute_input":"2022-07-01T01:50:54.067293Z","iopub.status.idle":"2022-07-01T01:50:55.903623Z","shell.execute_reply.started":"2022-07-01T01:50:54.067257Z","shell.execute_reply":"2022-07-01T01:50:55.902431Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"kwargs = {\n    \"finetuned_from\": model_name, \n    \"tasks\": \"token-classification\",\n    \"language\": 'mn'\n}\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T01:50:58.866452Z","iopub.execute_input":"2022-07-01T01:50:58.867123Z","iopub.status.idle":"2022-07-01T01:51:21.989944Z","shell.execute_reply.started":"2022-07-01T01:50:58.867081Z","shell.execute_reply":"2022-07-01T01:51:21.988484Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# raw_dataset.push_to_hub('mongolian-ner', token=hf_token)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## –¢”©–≥—Å–≥”©–ª\n","metadata":{}}]}